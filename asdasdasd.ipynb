{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>frameType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34541863</td>\n",
       "      <td>\"A\" Cell Breeding Device</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64163367</td>\n",
       "      <td>\"A\" Cell Incubator</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91231901</td>\n",
       "      <td>\"A\" Cell Recombination Device</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73262676</td>\n",
       "      <td>\"A\" Cell Scatter Burst</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98319530</td>\n",
       "      <td>\"Infernoble Arms - Almace\"</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12622</th>\n",
       "      <td>2648201</td>\n",
       "      <td>ZW - Sleipnir Mail</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12623</th>\n",
       "      <td>95886782</td>\n",
       "      <td>ZW - Sylphid Wing</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12624</th>\n",
       "      <td>81471108</td>\n",
       "      <td>ZW - Tornado Bringer</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12625</th>\n",
       "      <td>18865703</td>\n",
       "      <td>ZW - Ultimate Shield</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12626</th>\n",
       "      <td>76080032</td>\n",
       "      <td>ZW - Unicorn Spear</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                           name frameType\n",
       "0      34541863       \"A\" Cell Breeding Device     spell\n",
       "1      64163367             \"A\" Cell Incubator     spell\n",
       "2      91231901  \"A\" Cell Recombination Device     spell\n",
       "3      73262676         \"A\" Cell Scatter Burst     spell\n",
       "4      98319530     \"Infernoble Arms - Almace\"     spell\n",
       "...         ...                            ...       ...\n",
       "12622   2648201             ZW - Sleipnir Mail    effect\n",
       "12623  95886782              ZW - Sylphid Wing    effect\n",
       "12624  81471108           ZW - Tornado Bringer    effect\n",
       "12625  18865703           ZW - Ultimate Shield    effect\n",
       "12626  76080032             ZW - Unicorn Spear    effect\n",
       "\n",
       "[12627 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('deck.csv')\n",
    "\n",
    "df_c = df[[\"id\", \"name\", \"frameType\"]]\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "metadata = []\n",
    "for index, row in df_c.iterrows():\n",
    "    dir = f\"train/{row['frameType']}\"\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    try:\n",
    "        sourceImage = f\"images/{row['id']}.jpg\"\n",
    "        targetImage = f\"{dir}/{row['name']}.jpg\"\n",
    "\n",
    "        im = Image.open(sourceImage)\n",
    "        im = im.resize((512, 512), Image.Resampling.LANCZOS)\n",
    "        im.save(targetImage, \"JPEG\")\n",
    "\n",
    "        metadata.append({\n",
    "            'file_name': f\"{row['frameType']}/{row['name']}.jpg\",\n",
    "            'name': row['name'].replace(\"\\\"\", \"\"),\n",
    "            'frameType': row['frameType']\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_m = pd.DataFrame.from_dict(metadata)\n",
    "df_m.to_csv('train/metadata.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Resolving data files: 100%|██████████| 12428/12428 [00:01<00:00, 7783.77it/s]\n",
      "Resolving data files: 100%|██████████| 62/62 [00:00<?, ?it/s]\n",
      "Resolving data files: 100%|██████████| 3403/3403 [00:00<00:00, 8592.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to C:/Users/Fabio/.cache/huggingface/datasets/imagefolder/default-437712807363b603/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 12162/12162 [00:00<00:00, 18790.01it/s]\n",
      "Downloading data files: 100%|██████████| 267/267 [00:00<00:00, 15724.00it/s]\n",
      "Extracting data files: 100%|██████████| 267/267 [00:01<00:00, 175.05it/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Downloading data files: 100%|██████████| 62/62 [00:00<00:00, 20697.78it/s]\n",
      "Extracting data files: 100%|██████████| 62/62 [00:00<00:00, 213.67it/s]\n",
      "Downloading data files: 100%|██████████| 8/8 [00:00<?, ?it/s]\n",
      "Downloading data files: 100%|██████████| 3396/3396 [00:00<00:00, 19824.32it/s]\n",
      "Extracting data files: 100%|██████████| 3396/3396 [00:24<00:00, 136.65it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:1608\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1607\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m-> 1608\u001b[0m \u001b[39mfor\u001b[39;00m key, record \u001b[39min\u001b[39;00m generator:\n\u001b[0;32m   1609\u001b[0m     \u001b[39mif\u001b[39;00m max_shard_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m writer\u001b[39m.\u001b[39m_num_bytes \u001b[39m>\u001b[39m max_shard_size:\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\packaged_modules\\folder_based_builder\\folder_based_builder.py:304\u001b[0m, in \u001b[0;36mFolderBasedBuilder._generate_examples\u001b[1;34m(self, files, metadata_files, split_name, add_metadata, add_labels)\u001b[0m\n\u001b[0;32m    303\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOne or several metadata.\u001b[39m\u001b[39m{\u001b[39;00mmetadata_ext\u001b[39m}\u001b[39;00m\u001b[39m were found, but not in the same directory or in a parent directory of \u001b[39m\u001b[39m{\u001b[39;00mdownloaded_file_or_dir\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         )\n\u001b[0;32m    307\u001b[0m \u001b[39mif\u001b[39;00m metadata_dir \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m downloaded_metadata_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: One or several metadata.csv were found, but not in the same directory or in a parent directory of C:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\Lib\\site-packages\\networkx\\drawing\\tests\\baseline\\test_house_with_colors.png.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m----> 3\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mimagefolder\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m dataset\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\load.py:1797\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1794\u001b[0m try_from_hf_gcs \u001b[39m=\u001b[39m path \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[0;32m   1796\u001b[0m \u001b[39m# Download and prepare data\u001b[39;00m\n\u001b[1;32m-> 1797\u001b[0m builder_instance\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[0;32m   1798\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m   1799\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m   1800\u001b[0m     verification_mode\u001b[39m=\u001b[39;49mverification_mode,\n\u001b[0;32m   1801\u001b[0m     try_from_hf_gcs\u001b[39m=\u001b[39;49mtry_from_hf_gcs,\n\u001b[0;32m   1802\u001b[0m     num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m   1803\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   1804\u001b[0m )\n\u001b[0;32m   1806\u001b[0m \u001b[39m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[39m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[39mif\u001b[39;00m keep_in_memory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m is_small_dataset(builder_instance\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:890\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    889\u001b[0m         prepare_split_kwargs[\u001b[39m\"\u001b[39m\u001b[39mnum_proc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m num_proc\n\u001b[1;32m--> 890\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download_and_prepare(\n\u001b[0;32m    891\u001b[0m         dl_manager\u001b[39m=\u001b[39mdl_manager,\n\u001b[0;32m    892\u001b[0m         verification_mode\u001b[39m=\u001b[39mverification_mode,\n\u001b[0;32m    893\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_split_kwargs,\n\u001b[0;32m    894\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs,\n\u001b[0;32m    895\u001b[0m     )\n\u001b[0;32m    896\u001b[0m \u001b[39m# Sync info\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdataset_size \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(split\u001b[39m.\u001b[39mnum_bytes \u001b[39mfor\u001b[39;00m split \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39msplits\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:1649\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dl_manager, verification_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs):\n\u001b[1;32m-> 1649\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_download_and_prepare(\n\u001b[0;32m   1650\u001b[0m         dl_manager,\n\u001b[0;32m   1651\u001b[0m         verification_mode,\n\u001b[0;32m   1652\u001b[0m         check_duplicate_keys\u001b[39m=\u001b[39mverification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS\n\u001b[0;32m   1653\u001b[0m         \u001b[39mor\u001b[39;00m verification_mode \u001b[39m==\u001b[39m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS,\n\u001b[0;32m   1654\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_splits_kwargs,\n\u001b[0;32m   1655\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:985\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[0;32m    981\u001b[0m split_dict\u001b[39m.\u001b[39madd(split_generator\u001b[39m.\u001b[39msplit_info)\n\u001b[0;32m    983\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[1;32m--> 985\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_split(split_generator, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mprepare_split_kwargs)\n\u001b[0;32m    986\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    987\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m    988\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find data file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m         \u001b[39m+\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_download_instructions \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    990\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mOriginal error:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)\n\u001b[0;32m    992\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:1487\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split\u001b[1;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[0;32m   1485\u001b[0m job_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m   1486\u001b[0m \u001b[39mwith\u001b[39;00m pbar:\n\u001b[1;32m-> 1487\u001b[0m     \u001b[39mfor\u001b[39;00m job_id, done, content \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_split_single(\n\u001b[0;32m   1488\u001b[0m         gen_kwargs\u001b[39m=\u001b[39mgen_kwargs, job_id\u001b[39m=\u001b[39mjob_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_prepare_split_args\n\u001b[0;32m   1489\u001b[0m     ):\n\u001b[0;32m   1490\u001b[0m         \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   1491\u001b[0m             result \u001b[39m=\u001b[39m content\n",
      "File \u001b[1;32mc:\\Users\\Fabio\\ML2_Project\\ML2_Project\\venv\\lib\\site-packages\\datasets\\builder.py:1644\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._prepare_split_single\u001b[1;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[0;32m   1642\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, SchemaInferenceError) \u001b[39mand\u001b[39;00m e\u001b[39m.\u001b[39m__context__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1643\u001b[0m         e \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39m__context__\n\u001b[1;32m-> 1644\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetGenerationError(\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while generating the dataset\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m \u001b[39myield\u001b[39;00m job_id, \u001b[39mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer\u001b[39m.\u001b[39m_features, num_shards, shard_lengths)\n",
      "\u001b[1;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\".\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.push_to_hub(\"FabioArdi/test\", private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
